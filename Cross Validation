from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import mean_squared_log_error

log_y_train_predict = cross_val_predict(model, x_train, log_y_train, cv =5)
y_train_predict = np.exp(log_y_train_predict) - 1



random_state = 5




num_loop = 100

n_estimators = 1000



x_train, x_test, y_train, y_test = \
    train_test_split(x_train, y_train, test_size = 0.2, random_state = random_state)

coarse_hyperparameters_list = []

for loop in range(num_loop):
    
    
    
    min_samples_leaf = np.random.randint(2, 200)
    
    subsample = np.random.uniform(0.1, 1.0)
    
    min_samples_split = np.random.randint(10, 200)
    
    learning_rate = 10 ** -np.random.uniform(low = 1, high = 10)
    
    parameters = {'min_samples_leaf' : min_samples_leaf,
                  'subsample' : subsample,
                  'min_samples_split' : min_samples_split,
                  'learning_rate' : learning_rate,
                  'n_estimators' : n_estimators,
                  'random_state' : random_state}
    
    model = GradientBoostingRegressor(**parameters)
    
    log_x_train = np.log(1 + x_train)
    log_y_train = np.log(1 + y_train)
    log_x_test = np.log(1 + x_test)
    log_y_test = np.log(1 + y_test)
    
    log_y_train_predict = cross_val_predict(model, x_train, log_y_train, cv = 10)
    y_train_predict = np.exp(log_y_train_predict) - 1
    
    
   
    
    score = mean_squared_log_error(y_train_predict, y_train)
    score = np.sqrt(score)
    parameters['score'] = score
    
    print(f"min_samples_leaf = {min_samples_leaf}, min_samples_split = {min_samples_split}, subsample = {subsample}, \
          learning_rate = {learning_rate}, Score = {parameters['score']: 5f}")
    
    coarse_hyperparameters_list.append(parameters)
    coarse_hyperparameters_data = pd.DataFrame(coarse_hyperparameters_list)
    coarse_hyperparameters_data = coarse_hyperparameters_data.sort_values(by = "score")
    
    

coarse_hyperparameters_data.head(10)


#### Cross Validation + 하이퍼파라미터 튜닝!
